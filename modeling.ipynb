{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3),\n",
    "                            activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(128, activation = 'relu'))\n",
    "classifier.add(Dense(10, activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer= 'adam', loss= 'binary_crossentropy',\n",
    "                  metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Dennis Febri Dien\\\\Documents\\\\college\\\\ML\\\\MLM'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24000 images belonging to 10 classes.\n",
      "Found 3000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    './DATA/train_set',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_set = train_datagen.flow_from_directory(\n",
    "    './DATA/test_set',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.2910 - acc: 0.8976"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: [[[[0.21568629 0.30046007 0.3257969 ]\n   [0.21207076 0.30588236 0.32760403]\n   [0.20784315 0.30588236 0.3254902 ]\n   ...\n   [0.20873179 0.32637885 0.31853572]\n   [0.20511658 0.32276365 0.3149205 ]\n   [0.20876196 0.32640904 0.3185659 ]]\n\n  [[0.21568629 0.30046007 0.3257969 ]\n   [0.21207076 0.30588236 0.32760403]\n   [0.20784315 0.30588236 0.3254902 ]\n   ...\n   [0.20873179 0.32637885 0.31853572]\n   [0.20511658 0.32276365 0.3149205 ]\n   [0.20876196 0.32640904 0.3185659 ]]\n\n  [[0.21568629 0.30046007 0.3257969 ]\n   [0.21207076 0.30588236 0.32760403]\n   [0.20784315 0.30588236 0.3254902 ]\n   ...\n   [0.20873179 0.32637885 0.31853572]\n   [0.20511658 0.32276365 0.3149205 ]\n   [0.20876196 0.32640904 0.3185659 ]]\n\n  ...\n\n  [[0.2627451  0.35536206 0.34359735]\n   [0.23924422 0.34632227 0.33998084]\n   [0.21026334 0.32941177 0.33241454]\n   ...\n   [0.15382981 0.29197335 0.29803923]\n   [0.15294118 0.30110237 0.3007658 ]\n   [0.15536138 0.301042   0.2995406 ]]\n\n  [[0.2627451  0.35536206 0.34359735]\n   [0.23924422 0.34632227 0.33998084]\n   [0.21026334 0.32941177 0.33241454]\n   ...\n   [0.15382981 0.29197335 0.29803923]\n   [0.15294118 0.30110237 0.3007658 ]\n   [0.15536138 0.301042   0.2995406 ]]\n\n  [[0.2627451  0.35536206 0.34359735]\n   [0.23924422 0.34632227 0.33998084]\n   [0.21026334 0.32941177 0.33241454]\n   ...\n   [0.15382981 0.29197335 0.29803923]\n   [0.15294118 0.30110237 0.3007658 ]\n   [0.15536138 0.301042   0.2995406 ]]]\n\n\n [[[0.3629042  0.4078311  0.38251805]\n   [0.36280453 0.40776846 0.38244972]\n   [0.36270487 0.40770584 0.38238138]\n   ...\n   [0.33052137 0.3745539  0.37165377]\n   [0.33049288 0.37452257 0.37165663]\n   [0.33046442 0.37449124 0.37165946]]\n\n  [[0.50341374 0.5064724  0.48845935]\n   [0.5032686  0.5063442  0.48832554]\n   [0.50312334 0.5062161  0.4881917 ]\n   ...\n   [0.39009947 0.43279222 0.38733926]\n   [0.38996562 0.4326783  0.38725382]\n   [0.3898318  0.4325644  0.3871684 ]]\n\n  [[0.63855475 0.624972   0.6147849 ]\n   [0.63868576 0.6250916  0.61489594]\n   [0.6388167  0.6252111  0.61500704]\n   ...\n   [0.54685897 0.56259286 0.4855702 ]\n   [0.5468448  0.5626099  0.48557585]\n   [0.54683053 0.562627   0.48558158]]\n\n  ...\n\n  [[0.3893808  0.4213261  0.49640864]\n   [0.3893637  0.42130047 0.49637446]\n   [0.38934663 0.42127484 0.49634027]\n   ...\n   [0.3962506  0.411868   0.4550225 ]\n   [0.3962221  0.41185093 0.45500255]\n   [0.39619365 0.41183385 0.4549826 ]]\n\n  [[0.41128093 0.4541763  0.54020894]\n   [0.41126385 0.45415065 0.5401747 ]\n   [0.41124678 0.45412505 0.54014057]\n   ...\n   [0.43275082 0.43376815 0.48057267]\n   [0.43272236 0.43375105 0.4805527 ]\n   [0.43269387 0.43373397 0.48053277]]\n\n  [[0.4153341  0.43705505 0.5161908 ]\n   [0.41533127 0.43706927 0.51621073]\n   [0.41532844 0.4370835  0.51623064]\n   ...\n   [0.4454812  0.4454812  0.48574865]\n   [0.4454727  0.4454727  0.48574582]\n   [0.44546413 0.44546413 0.48574296]]]\n\n\n [[[0.5764706  0.49411768 0.4901961 ]\n   [0.5764706  0.49411768 0.4901961 ]\n   [0.5764706  0.49411768 0.4901961 ]\n   ...\n   [0.4784314  0.42352945 0.42352945]\n   [0.4784314  0.42352945 0.42352945]\n   [0.4784314  0.42352945 0.42352945]]\n\n  [[0.5764706  0.49411768 0.4901961 ]\n   [0.5764706  0.49411768 0.4901961 ]\n   [0.5764706  0.49411768 0.4901961 ]\n   ...\n   [0.4784314  0.42352945 0.42352945]\n   [0.4784314  0.42352945 0.42352945]\n   [0.4784314  0.42352945 0.42352945]]\n\n  [[0.572337   0.49515107 0.49536318]\n   [0.57234854 0.49514818 0.4953487 ]\n   [0.57236016 0.4951453  0.49533418]\n   ...\n   [0.47586176 0.424386   0.4252425 ]\n   [0.47587046 0.4243831  0.4252367 ]\n   [0.47587916 0.42438018 0.42523095]]\n\n  ...\n\n  [[0.6770717  0.5986454  0.58296424]\n   [0.6769818  0.5985642  0.58289176]\n   [0.6768919  0.598483   0.5828192 ]\n   ...\n   [0.63690126 0.5780777  0.55846983]\n   [0.6369273  0.5781038  0.55849594]\n   [0.6369534  0.5781299  0.55852205]]\n\n  [[0.7176471  0.63529414 0.6156863 ]\n   [0.7176471  0.63529414 0.6156863 ]\n   [0.7176471  0.63529414 0.6156863 ]\n   ...\n   [0.62352943 0.5647059  0.54509807]\n   [0.62352943 0.5647059  0.54509807]\n   [0.62352943 0.5647059  0.54509807]]\n\n  [[0.7176471  0.63529414 0.6156863 ]\n   [0.7176471  0.63529414 0.6156863 ]\n   [0.7176471  0.63529414 0.6156863 ]\n   ...\n   [0.62352943 0.5647059  0.54509807]\n   [0.62352943 0.5647059  0.54509807]\n   [0.62352943 0.5647059  0.54509807]]]\n\n\n ...\n\n\n [[[0.69914114 0.5926254  0.59105504]\n   [0.75630975 0.5500409  0.51814365]\n   [0.69687694 0.50447625 0.4704801 ]\n   ...\n   [0.5890118  0.45866305 0.4782709 ]\n   [0.57753646 0.4297225  0.4544576 ]\n   [0.49963787 0.41895086 0.44854885]]\n\n  [[0.69914114 0.5926254  0.59105504]\n   [0.75630975 0.5500409  0.51814365]\n   [0.69687694 0.50447625 0.4704801 ]\n   ...\n   [0.5890118  0.45866305 0.4782709 ]\n   [0.57753646 0.4297225  0.4544576 ]\n   [0.49963787 0.41895086 0.44854885]]\n\n  [[0.69914114 0.5926254  0.59105504]\n   [0.75630975 0.5500409  0.51814365]\n   [0.69687694 0.50447625 0.4704801 ]\n   ...\n   [0.5890118  0.45866305 0.4782709 ]\n   [0.57753646 0.4297225  0.4544576 ]\n   [0.49963787 0.41895086 0.44854885]]\n\n  ...\n\n  [[0.607058   0.54243016 0.5494881 ]\n   [0.5884836  0.5210439  0.5152998 ]\n   [0.55962205 0.51386124 0.52235335]\n   ...\n   [0.5300452  0.49333686 0.4942782 ]\n   [0.472403   0.46681896 0.4719462 ]\n   [0.53396976 0.5056858  0.5070878 ]]\n\n  [[0.607058   0.54243016 0.5494881 ]\n   [0.5884836  0.5210439  0.5152998 ]\n   [0.55962205 0.51386124 0.52235335]\n   ...\n   [0.5300452  0.49333686 0.4942782 ]\n   [0.472403   0.46681896 0.4719462 ]\n   [0.53396976 0.5056858  0.5070878 ]]\n\n  [[0.607058   0.54243016 0.5494881 ]\n   [0.5884836  0.5210439  0.5152998 ]\n   [0.55962205 0.51386124 0.52235335]\n   ...\n   [0.5300452  0.49333686 0.4942782 ]\n   [0.472403   0.46681896 0.4719462 ]\n   [0.53396976 0.5056858  0.5070878 ]]]\n\n\n [[[0.6001439  0.512918   0.47681636]\n   [0.6773898  0.5536499  0.51163363]\n   [0.7432156  0.5698286  0.51859236]\n   ...\n   [0.9854989  0.85852784 0.7625634 ]\n   [0.99004066 0.89220434 0.77770257]\n   [0.98364574 0.8992351  0.77460676]]\n\n  [[0.63727003 0.53187156 0.51177984]\n   [0.6993884  0.5753475  0.54589176]\n   [0.7323393  0.5813233  0.53881335]\n   ...\n   [0.9785404  0.8481505  0.76590335]\n   [0.9610479  0.8414144  0.75039595]\n   [0.9600131  0.8510683  0.7491572 ]]\n\n  [[0.6382319  0.5217696  0.5186656 ]\n   [0.6443619  0.5303728  0.5188453 ]\n   [0.6413708  0.5272979  0.50378615]\n   ...\n   [0.8676159  0.6911868  0.63487947]\n   [0.79935706 0.63711125 0.5868444 ]\n   [0.7932556  0.6462924  0.59225154]]\n\n  ...\n\n  [[0.40013102 0.37248355 0.40000004]\n   [0.39680663 0.36930925 0.3967757 ]\n   [0.39604497 0.368594   0.39604497]\n   ...\n   [0.37229544 0.4378176  0.4407955 ]\n   [0.41263047 0.4325423  0.42724866]\n   [0.43451527 0.42430833 0.4098791 ]]\n\n  [[0.40356904 0.37611806 0.40356904]\n   [0.3976336  0.3730027  0.3919935 ]\n   [0.39607847 0.3693406  0.3946522 ]\n   ...\n   [0.34428418 0.44396368 0.43367988]\n   [0.36881322 0.43727362 0.43040264]\n   [0.3832771  0.430457   0.4237886 ]]\n\n  [[0.40720356 0.4027263  0.41376746]\n   [0.39320377 0.38917768 0.39872232]\n   [0.3869417  0.37986273 0.398423  ]\n   ...\n   [0.33519462 0.44713777 0.43313706]\n   [0.34308964 0.44686934 0.43929118]\n   [0.34687617 0.44496712 0.43832663]]]\n\n\n [[[0.84683853 0.7495654  0.68919843]\n   [0.9339476  0.832898   0.7582153 ]\n   [0.94303405 0.82952106 0.74694604]\n   ...\n   [0.62205374 0.56061286 0.52258044]\n   [0.60269403 0.5452248  0.5047962 ]\n   [0.58944964 0.52890986 0.49460715]]\n\n  [[0.90956414 0.7938371  0.7180184 ]\n   [0.9157601  0.8057052  0.7246224 ]\n   [0.8864274  0.7731508  0.695535  ]\n   ...\n   [0.60163236 0.5429525  0.5125767 ]\n   [0.59499866 0.5379081  0.5069912 ]\n   [0.58965665 0.53531384 0.50968057]]\n\n  [[0.9179593  0.79313153 0.71238714]\n   [0.8891044  0.7710357  0.69031847]\n   [0.8384218  0.7263177  0.65326345]\n   ...\n   [0.5941092  0.5339278  0.50579786]\n   [0.61079174 0.54848975 0.5174095 ]\n   [0.612236   0.55610085 0.527388  ]]\n\n  ...\n\n  [[0.5701937  0.48826802 0.4713444 ]\n   [0.60771066 0.52770597 0.50380045]\n   [0.6340576  0.55529916 0.5237357 ]\n   ...\n   [0.62207997 0.562506   0.5631278 ]\n   [0.6989647  0.62954843 0.6086012 ]\n   [0.6951753  0.6230806  0.58344096]]\n\n  [[0.5736928  0.49145427 0.47278202]\n   [0.60457325 0.5231887  0.501644  ]\n   [0.62304014 0.5435738  0.51663333]\n   ...\n   [0.7153235  0.6302588  0.6151795 ]\n   [0.7841791  0.69169164 0.6614221 ]\n   [0.75720894 0.6689148  0.6254333 ]]\n\n  [[0.5821301  0.50017416 0.48508325]\n   [0.60650736 0.5241544  0.5089385 ]\n   [0.61711246 0.5358124  0.5184771 ]\n   ...\n   [0.8077799  0.6996103  0.666319  ]\n   [0.8367441  0.72389793 0.6846734 ]\n   [0.77418196 0.6706731  0.6286314 ]]]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b15bd2ed00d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                         validation_steps=100)\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\envs\\DSA\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1777\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1778\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1779\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\DSA\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                 max_queue_size=max_queue_size)\n\u001b[0m\u001b[0;32m    226\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;31m# No need for try/except because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\DSA\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m    333\u001b[0m         raise ValueError('Output of generator should be a tuple '\n\u001b[0;32m    334\u001b[0m                          \u001b[1;34m'(x, y, sample_weight) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m                          'or (x, y). Found: ' + str(generator_output))\n\u001b[0m\u001b[0;32m    336\u001b[0m       \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: [[[[0.21568629 0.30046007 0.3257969 ]\n   [0.21207076 0.30588236 0.32760403]\n   [0.20784315 0.30588236 0.3254902 ]\n   ...\n   [0.20873179 0.32637885 0.31853572]\n   [0.20511658 0.32276365 0.3149205 ]\n   [0.20876196 0.32640904 0.3185659 ]]\n\n  [[0.21568629 0.30046007 0.3257969 ]\n   [0.21207076 0.30588236 0.32760403]\n   [0.20784315 0.30588236 0.3254902 ]\n   ...\n   [0.20873179 0.32637885 0.31853572]\n   [0.20511658 0.32276365 0.3149205 ]\n   [0.20876196 0.32640904 0.3185659 ]]\n\n  [[0.21568629 0.30046007 0.3257969 ]\n   [0.21207076 0.30588236 0.32760403]\n   [0.20784315 0.30588236 0.3254902 ]\n   ...\n   [0.20873179 0.32637885 0.31853572]\n   [0.20511658 0.32276365 0.3149205 ]\n   [0.20876196 0.32640904 0.3185659 ]]\n\n  ...\n\n  [[0.2627451  0.35536206 0.34359735]\n   [0.23924422 0.34632227 0.33998084]\n   [0.21026334 0.32941177 0.33241454]\n   ...\n   [0.15382981 0.29197335 0.29803923]\n   [0.15294118 0.30110237 0.3007658 ]\n   [0.15536138 0.301042   0.2995406 ]]\n\n  [[0.2627451  0.35536206 0.34359735]\n   [0.23924422 0.34632227 0.33998084]\n   [0.21026334 0.32941177 0.33241454]\n   ...\n   [0.15382981 0.29197335 0.29803923]\n   [0.15294118 0.30110237 0.3007658 ]\n   [0.15536138 0.301042   0.2995406 ]]\n\n  [[0.2627451  0.35536206 0.34359735]\n   [0.23924422 0.34632227 0.33998084]\n   [0.21026334 0.32941177 0.33241454]\n   ...\n   [0.15382981 0.29197335 0.29803923]\n   [0.15294118 0.30110237 0.3007658 ]\n   [0.15536138 0.301042   0.2995406 ]]]\n\n\n [[[0.3629042  0.4078311  0.38251805]\n   [0.36280453 0.40776846 0.38244972]\n   [0.36270487 0.40770584 0.38238138]\n   ...\n   [0.33052137 0.3745539  0.37165377]\n   [0.33049288 0.37452257 0.37165663]\n   [0.33046442 0.37449124 0.37165946]]\n\n  [[0.50341374 0.5064724  0.48845935]\n   [0.5032686  0.5063442  0.48832554]\n   [0.50312334 0.5062161  0.4881917 ]\n   ...\n   [0.39009947 0.43279222 0.38733926]\n   [0.38996562 0.4326783  0.38725382]\n   [0.3898318  0.4325644  0.3871684 ]]\n\n  [[0.63855475 0.624972   0.6147849 ]\n   [0.63868576 0.6250916  0.61489594]\n   [0.6388167  0.6252111  0.61500704]\n   ...\n   [0.54685897 0.56259286 0.4855702 ]\n   [0.5468448  0.5626099  0.48557585]\n   [0.54683053 0.562627   0.48558158]]\n\n  ...\n\n  [[0.3893808  0.4213261  0.49640864]\n   [0.3893637  0.42130047 0.49637446]\n   [0.38934663 0.42127484 0.49634027]\n   ...\n   [0.3962506  0.411868   0.4550225 ]\n   [0.3962221  0.41185093 0.45500255]\n   [0.39619365 0.41183385 0.4549826 ]]\n\n  [[0.41128093 0.4541763  0.54020894]\n   [0.41126385 0.45415065 0.5401747 ]\n   [0.41124678 0.45412505 0.54014057]\n   ...\n   [0.43275082 0.43376815 0.48057267]\n   [0.43272236 0.43375105 0.4805527 ]\n   [0.43269387 0.43373397 0.48053277]]\n\n  [[0.4153341  0.43705505 0.5161908 ]\n   [0.41533127 0.43706927 0.51621073]\n   [0.41532844 0.4370835  0.51623064]\n   ...\n   [0.4454812  0.4454812  0.48574865]\n   [0.4454727  0.4454727  0.48574582]\n   [0.44546413 0.44546413 0.48574296]]]\n\n\n [[[0.5764706  0.49411768 0.4901961 ]\n   [0.5764706  0.49411768 0.4901961 ]\n   [0.5764706  0.49411768 0.4901961 ]\n   ...\n   [0.4784314  0.42352945 0.42352945]\n   [0.4784314  0.42352945 0.42352945]\n   [0.4784314  0.42352945 0.42352945]]\n\n  [[0.5764706  0.49411768 0.4901961 ]\n   [0.5764706  0.49411768 0.4901961 ]\n   [0.5764706  0.49411768 0.4901961 ]\n   ...\n   [0.4784314  0.42352945 0.42352945]\n   [0.4784314  0.42352945 0.42352945]\n   [0.4784314  0.42352945 0.42352945]]\n\n  [[0.572337   0.49515107 0.49536318]\n   [0.57234854 0.49514818 0.4953487 ]\n   [0.57236016 0.4951453  0.49533418]\n   ...\n   [0.47586176 0.424386   0.4252425 ]\n   [0.47587046 0.4243831  0.4252367 ]\n   [0.47587916 0.42438018 0.42523095]]\n\n  ...\n\n  [[0.6770717  0.5986454  0.58296424]\n   [0.6769818  0.5985642  0.58289176]\n   [0.6768919  0.598483   0.5828192 ]\n   ...\n   [0.63690126 0.5780777  0.55846983]\n   [0.6369273  0.5781038  0.55849594]\n   [0.6369534  0.5781299  0.55852205]]\n\n  [[0.7176471  0.63529414 0.6156863 ]\n   [0.7176471  0.63529414 0.6156863 ]\n   [0.7176471  0.63529414 0.6156863 ]\n   ...\n   [0.62352943 0.5647059  0.54509807]\n   [0.62352943 0.5647059  0.54509807]\n   [0.62352943 0.5647059  0.54509807]]\n\n  [[0.7176471  0.63529414 0.6156863 ]\n   [0.7176471  0.63529414 0.6156863 ]\n   [0.7176471  0.63529414 0.6156863 ]\n   ...\n   [0.62352943 0.5647059  0.54509807]\n   [0.62352943 0.5647059  0.54509807]\n   [0.62352943 0.5647059  0.54509807]]]\n\n\n ...\n\n\n [[[0.69914114 0.5926254  0.59105504]\n   [0.75630975 0.5500409  0.51814365]\n   [0.69687694 0.50447625 0.4704801 ]\n   ...\n   [0.5890118  0.45866305 0.4782709 ]\n   [0.57753646 0.4297225  0.4544576 ]\n   [0.49963787 0.41895086 0.44854885]]\n\n  [[0.69914114 0.5926254  0.59105504]\n   [0.75630975 0.5500409  0.51814365]\n   [0.69687694 0.50447625 0.4704801 ]\n   ...\n   [0.5890118  0.45866305 0.4782709 ]\n   [0.57753646 0.4297225  0.4544576 ]\n   [0.49963787 0.41895086 0.44854885]]\n\n  [[0.69914114 0.5926254  0.59105504]\n   [0.75630975 0.5500409  0.51814365]\n   [0.69687694 0.50447625 0.4704801 ]\n   ...\n   [0.5890118  0.45866305 0.4782709 ]\n   [0.57753646 0.4297225  0.4544576 ]\n   [0.49963787 0.41895086 0.44854885]]\n\n  ...\n\n  [[0.607058   0.54243016 0.5494881 ]\n   [0.5884836  0.5210439  0.5152998 ]\n   [0.55962205 0.51386124 0.52235335]\n   ...\n   [0.5300452  0.49333686 0.4942782 ]\n   [0.472403   0.46681896 0.4719462 ]\n   [0.53396976 0.5056858  0.5070878 ]]\n\n  [[0.607058   0.54243016 0.5494881 ]\n   [0.5884836  0.5210439  0.5152998 ]\n   [0.55962205 0.51386124 0.52235335]\n   ...\n   [0.5300452  0.49333686 0.4942782 ]\n   [0.472403   0.46681896 0.4719462 ]\n   [0.53396976 0.5056858  0.5070878 ]]\n\n  [[0.607058   0.54243016 0.5494881 ]\n   [0.5884836  0.5210439  0.5152998 ]\n   [0.55962205 0.51386124 0.52235335]\n   ...\n   [0.5300452  0.49333686 0.4942782 ]\n   [0.472403   0.46681896 0.4719462 ]\n   [0.53396976 0.5056858  0.5070878 ]]]\n\n\n [[[0.6001439  0.512918   0.47681636]\n   [0.6773898  0.5536499  0.51163363]\n   [0.7432156  0.5698286  0.51859236]\n   ...\n   [0.9854989  0.85852784 0.7625634 ]\n   [0.99004066 0.89220434 0.77770257]\n   [0.98364574 0.8992351  0.77460676]]\n\n  [[0.63727003 0.53187156 0.51177984]\n   [0.6993884  0.5753475  0.54589176]\n   [0.7323393  0.5813233  0.53881335]\n   ...\n   [0.9785404  0.8481505  0.76590335]\n   [0.9610479  0.8414144  0.75039595]\n   [0.9600131  0.8510683  0.7491572 ]]\n\n  [[0.6382319  0.5217696  0.5186656 ]\n   [0.6443619  0.5303728  0.5188453 ]\n   [0.6413708  0.5272979  0.50378615]\n   ...\n   [0.8676159  0.6911868  0.63487947]\n   [0.79935706 0.63711125 0.5868444 ]\n   [0.7932556  0.6462924  0.59225154]]\n\n  ...\n\n  [[0.40013102 0.37248355 0.40000004]\n   [0.39680663 0.36930925 0.3967757 ]\n   [0.39604497 0.368594   0.39604497]\n   ...\n   [0.37229544 0.4378176  0.4407955 ]\n   [0.41263047 0.4325423  0.42724866]\n   [0.43451527 0.42430833 0.4098791 ]]\n\n  [[0.40356904 0.37611806 0.40356904]\n   [0.3976336  0.3730027  0.3919935 ]\n   [0.39607847 0.3693406  0.3946522 ]\n   ...\n   [0.34428418 0.44396368 0.43367988]\n   [0.36881322 0.43727362 0.43040264]\n   [0.3832771  0.430457   0.4237886 ]]\n\n  [[0.40720356 0.4027263  0.41376746]\n   [0.39320377 0.38917768 0.39872232]\n   [0.3869417  0.37986273 0.398423  ]\n   ...\n   [0.33519462 0.44713777 0.43313706]\n   [0.34308964 0.44686934 0.43929118]\n   [0.34687617 0.44496712 0.43832663]]]\n\n\n [[[0.84683853 0.7495654  0.68919843]\n   [0.9339476  0.832898   0.7582153 ]\n   [0.94303405 0.82952106 0.74694604]\n   ...\n   [0.62205374 0.56061286 0.52258044]\n   [0.60269403 0.5452248  0.5047962 ]\n   [0.58944964 0.52890986 0.49460715]]\n\n  [[0.90956414 0.7938371  0.7180184 ]\n   [0.9157601  0.8057052  0.7246224 ]\n   [0.8864274  0.7731508  0.695535  ]\n   ...\n   [0.60163236 0.5429525  0.5125767 ]\n   [0.59499866 0.5379081  0.5069912 ]\n   [0.58965665 0.53531384 0.50968057]]\n\n  [[0.9179593  0.79313153 0.71238714]\n   [0.8891044  0.7710357  0.69031847]\n   [0.8384218  0.7263177  0.65326345]\n   ...\n   [0.5941092  0.5339278  0.50579786]\n   [0.61079174 0.54848975 0.5174095 ]\n   [0.612236   0.55610085 0.527388  ]]\n\n  ...\n\n  [[0.5701937  0.48826802 0.4713444 ]\n   [0.60771066 0.52770597 0.50380045]\n   [0.6340576  0.55529916 0.5237357 ]\n   ...\n   [0.62207997 0.562506   0.5631278 ]\n   [0.6989647  0.62954843 0.6086012 ]\n   [0.6951753  0.6230806  0.58344096]]\n\n  [[0.5736928  0.49145427 0.47278202]\n   [0.60457325 0.5231887  0.501644  ]\n   [0.62304014 0.5435738  0.51663333]\n   ...\n   [0.7153235  0.6302588  0.6151795 ]\n   [0.7841791  0.69169164 0.6614221 ]\n   [0.75720894 0.6689148  0.6254333 ]]\n\n  [[0.5821301  0.50017416 0.48508325]\n   [0.60650736 0.5241544  0.5089385 ]\n   [0.61711246 0.5358124  0.5184771 ]\n   ...\n   [0.8077799  0.6996103  0.666319  ]\n   [0.8367441  0.72389793 0.6846734 ]\n   [0.77418196 0.6706731  0.6286314 ]]]]"
     ]
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                        steps_per_epoch=200,\n",
    "                        epochs=10,\n",
    "                        validation_data=test_set,\n",
    "                        validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
